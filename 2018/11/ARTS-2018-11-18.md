
 [Algorithm leetcode_872](#algorithm)

 [Review 聊聊Java里面的引用传递](#review)

 [Technique spark2.1版本中遇到的一个bug](#technique)

 [Share Mac系统更换brew源的方法](#share)


# Algorithm

https://leetcode.com/problems/leaf-similar-trees/

```java
    public static boolean leafSimilar(TreeNode root1,TreeNode root2){
        //比较两颗子树的叶子节点是否相似
        List<Integer> list1=new ArrayList<>();
        List<Integer> list2=new ArrayList<>();

        dfs(root1,list1);
        dfs(root2,list2);

        return list1.equals(list2);
    }

    public static void dfs(TreeNode n,List<Integer> list){
        if(n==null) return;
        if(n.left==null&&n.right==null){
            list.add(n.val);//叶子节点
        }
        dfs(n.left,list);//左边递归
        dfs(n.right,list);//右边递归

    }


    public static void main(String[] args) {
        leafSimilar(TreeNode.getRoot(),TreeNode.getRoot());
    }

```


# Review

 聊聊Java里面的"引用传递"

 长久以来，在Java语言里面一直有一个争论，就是Java语言到底是值传递（pass-by-value）还是引用传递（pass-by-reference），有的人说是值传递，有的人说是引用传递，两边各执一词，从而误导了很多开发者，更有甚者告诉开发者说不必纠结Java到底是值传递还是引用传递，只要能用就行了，但事实真的是这样吗？ 答案是否定的。

 为了弄清这两个概念，我们先要理解这两个概念本身的意思：

 首先值传递本身这个名字，我感觉就误导了不少人，对于值传递你可以理解成是数据的内存地址传递，并非是数据本身，或者叫它是指针。在维基百科里面，关于指针有清晰的描述：

 In computer science, a pointer is a programming language object that stores the memory address of another value located in computer memory. A pointer references a location in memory。

 然后，我们看引用传递中的引用的在维基百科上的描述：

 In computer science, a reference is a value that enables a program to indirectly access a particular datum, such as a variable's value or a record, in the computer's memory or in some other storage device.

 简单的说，引用本身就代表了数据，改变引用相当于改变了数据本身。


 根据概念的定义再回到Java语言里面，就会发现对Java本身来说，它只有指针传递也就是值传递，并非是引用传递。到这里，我相信有一部分读者可能已经接受不了，因为在Java里面大多数时候，我们都是讲基本类型，引用类型，从没听过什么指针的概念。导致这样的原因其实跟早期的Sun公司宣传策略有关系，我们知道Java语言，其实是从C语言借鉴改进过来的，其中一个主要的优点就是不允许我们像C那样可以通过指针直接操作内存区域，为了这个事情，Sun公司替换了概念称Java的指针为引用，从而在Java语言的发展历程中导致了更大的困惑，持续演变至今。事实就是Sun公司命名错误，当然Java已经发展了很多年，Oracle接盘后也犯不上纠正命名的问题。结果就是懂的人永远都知道是怎么回事，不懂的人一直分不清这两个概念。


 只有认清了Java里面存在指针，承认指针，我们才能更加自信的理解Java语言。

 我们来看一个简单的例子：

 ```
 class Dog{
        public String name;

        public Dog() {
        }

        public Dog(String name) {
             this.name = name;
         }
 	}
 ```
 然后，我们试着创建一个Dog对象：
 ```
 Dog dog=null; //1
 System.out.println(dog.name);
 dog=new Dog();//2

 ```
 然后运行一下，我们会看到一个异常：
 ```
 Exception in thread "main" java.lang.NullPointerException
 ```
 注意这个异常，叫空指针异常，在Java里面任何对象没有初始化的时候，如果我们使用其内部属性，就会抛出上面的信息，这也从侧面反映了dog这个变量的作用，其实就是指针，而并非引用。对于已经实例化的对象，如果我们没有重写toString方法，打印指针会得到一串类名组合+内存地址转换的十六进制字符串。

 我们接着来看一个例子：


 ```
     public static void change(String point){
        point="new value";
     }

     public static void swapString(){
         String orgin="orgin";
         System.out.println(orgin);
         change(orgin);
         System.out.println("==================after==================");
         System.out.println(orgin);


     }
 ```

 如果在main方法里面，执行swapString()方法，输出的结果都是orgin。

 对于Dog对象也一样，如下：
 ```
     public static void change(Dog dog){
        dog=new Dog("CAT");
        dog.name="cat";
     }


     public static void swapDog(){
         Dog dog=new Dog("tom");
         System.out.println(dog.name);
         change(dog);
         System.out.println("==================after==================");
         System.out.println(dog.name);
     }
 ```

 最终输出的结果都是tom，好像从未执行过change方法一样。
 ```
 tom
 ==================after==================
 tom
 ```


 这是为什么？ 你可能要说很简单啊，方法里面的作用域，只在方法里生效，出了方法就无效了。真的是这样吗？ 接着看下面，我们稍微改动一下change方法：

 ```
     public static void change(Dog dog){
 	   dog.name="new_tom";
        dog=new Dog("CAT");
        dog.name="cat";
     }
 ```

 同样，在main方法执行，输出的结果是：
 ```
 tom
 ==================after==================
 new_tom
 ```

 这里面，如果不理解值传递（指针传递）和引用传递的区别，其实是很难明白原因的：


 ```
     public static void change(Dog dog){
        dog=new Dog("CAT");//3 memory location：8888
        dog.name="cat";//4
     }


     public static void swapDog(){
         Dog dog=new Dog("tom");//1  memory location：7777
         System.out.println(dog.name);
         change(dog);//2
         System.out.println("==================after==================");
         System.out.println(dog.name);
     }
 ```

 我们加上序号之后，来分析一下，首先在第一步，我们创建了一个Dog对象，其中dog变量是指针（或者按Java的习惯叫引用，但其实是不正确的），指针存的是内存地址，而并非是内存中的数据本身，我们假设内存地址是7777，然后在第二步，将dog（指针）引用，传给了change方法，在第三步，因为我们新创建了一个Dog，并把dog指针指向了新的对象，这里假设其在堆上的内存地址是8888，然后并给内存地址=8888的Dog对象的name赋值了cat，然后方法执行结束，最后回到swapDog方法，继续执行，此时swapDog方法dog对象的指针仍然是7777，所以并没有任何变化。

 图示如下：

 [img]

 注意change方法执行后，没有指针指向内存地址8888的对象，故会在下一次gc时回收。

 接着我们分析下，微调后的change方法：
 ```
     public static void change(Dog dog){
 	   dog.name="new_tom";// 2.1
        dog=new Dog("CAT");
        dog.name="cat";
     }
 ```

 在第2.1步，我们通过dog指针=7777的数据，重新改变了其名称，这意味着内存地址7777的数据，被修改了，后面的两行改的是内存地址=8888的数据，所以最终结果是改变后的。


 注意，如果Java语言是引用传递的话，那么最终的结果name肯定是cat，因为引用传递的修改，指的就是数据本身，而并非地址。



 上面关于值传递（指针传递）和引用传递，说的有点抽象，我打个比方：

 指针指的是你的名字，通过指针可以找到数据本身，然后操作数据，但如果指针本身（非数据本身）变了，也就是你名字变了，但其实跟你没有关系，你自己还是你自己，你可以重新在换个名字代表你。

 引用指的是你本身，如果本身变了，比如你换了个发型，这个时候，无论你换多个名字（指针），你都一样是你，改变不了你发型换了的事实。

 所以，这个时候如果按照值传递（指针传递）的理解，来看上面的例子，你就会恍然大悟。在change方法里面dog的指针已经被替换成了8888，而8888地址代表的是新的对象
 所以不会改变7777的对象的内容，在微调后的版本中，我们直接改变了7777地址数据的name，所以最终的结果也是改变后的。


 总结：

 Java语言本身是值传递，也叫做指针传递，虽然我们一直叫引用类型，但其实它实际上是一个指针，而真正的引用传递改变的是数据本身的内容，如Lisp和Fortran语言，无论哪种方式，我们只要理解了其本质，就可以掌握的更好。




 参考链接：

 http://tutorials.jenkov.com/java-concurrency/java-memory-model.html

 https://www.guru99.com/java-stack-heap.html


 https://stackoverflow.com/questions/40480/is-java-pass-by-reference-or-pass-by-value?answertab=votes#tab-top


 https://stackoverflow.com/questions/41956753/do-multiple-threads-using-the-same-object-in-java-make-a-copy-of-it


 https://en.wikipedia.org/wiki/Reference_(computer_science)#Language_support

 https://en.wikipedia.org/wiki/Pointer_(computer_programming)

 http://www.javadude.com/articles/passbyvalue.htm


# Technique




今天生产环境的一个spark导出数据到ES的任务，被反映执行时间过长，平时用时在半小时左右，今天已经执行了3个半小时，还没结束。

上去看了一下，是一个读取hive表数据导入到ES的任务，整个表的数据量1亿+，大小约15G。

spark任务执行关键参数是：10个executor，每个executor分配5G内存，并使用5个core。

第一时间先去看Yarn的log是否有异常（spark运行在yarn上），进入监控页面之后，发现并无异常，但看到有一个task，耗时不正常，其他的任务都花费5,6分钟就结束了，这个task运行了近3个多小时，第一时间想到是否是数据倾斜导致的？但看了shuffle读取的数据量与其他的task读取的大小差不多，然后接着看这个任务的log，发现并无异常，这种现象挺奇怪的，没有异常也没有数据倾斜，为何处理时间花的这么久？

随后，观察es的数据量，发现并无增长变化，这个时候怀疑任务是不是死锁了，导致整个Job阻塞，迟迟结束不了。  点击spark监控页面上的Executors面板，可以看当前Executor（JVM进程）的Thread Dump的日志，点击进去之后，发现一个线程为Executor task launch worker-10的线程log如下：

```
sun.misc.Unsafe.park(Native Method)
java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:309)
org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:54)
scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:66)
org.elasticsearch.spark.sql.EsSparkSQL$$anonfun$saveToEs$1.apply(EsSparkSQL.scala:94)
org.elasticsearch.spark.sql.EsSparkSQL$$anonfun$saveToEs$1.apply(EsSparkSQL.scala:94)
org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
org.apache.spark.scheduler.Task.run(Task.scala:99)
org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
java.lang.Thread.run(Thread.java:745)
```

注意上面日志中的，这个类：

```
java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:309)
```

ShuffleBlockFetcherIterator类里的next方法，调用了LinkedBlockingQueue的take方法，导致这个worker线程一直在等待，阻塞队列LinkedBlockingQueue如果是空的时候，去调用take方法，会阻塞调用线程，这是阻塞队列最基本的特征，所以这个应该是不是根本原因，继续看线程的dump文件，发现有一个线程名为shuffle-client-5-1的线程有点问题，其执行代码状态一直处于某个方法，这就奇怪了，这个地方没有任何的同步和锁的服务，或者操作系统的挂起命令，但一直处于该初，说明应该是陷入死循环了，如下：

```
io.netty.util.Recycler$Stack.scavengeSome(Recycler.java:504)
io.netty.util.Recycler$Stack.scavenge(Recycler.java:454)
io.netty.util.Recycler$Stack.pop(Recycler.java:435)
io.netty.util.Recycler.get(Recycler.java:144)
io.netty.buffer.PooledUnsafeDirectByteBuf.newInstance(PooledUnsafeDirectByteBuf.java:39)
io.netty.buffer.PoolArena$DirectArena.newByteBuf(PoolArena.java:727)
io.netty.buffer.PoolArena.allocate(PoolArena.java:140)
io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:271)
io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:177)
io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:168)
io.netty.buffer.AbstractByteBufAllocator.ioBuffer(AbstractByteBufAllocator.java:129)
io.netty.channel.AdaptiveRecvByteBufAllocator$HandleImpl.allocate(AdaptiveRecvByteBufAllocator.java:104)
io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:117)
io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652)
io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
java.lang.Thread.run(Thread.java:745)
```


这个线程是属于netty的，这里简单介绍一下，spark在做shuffer的时候是通过netty来传输数据的，shuffer的时候会在map侧启动shuffer-server提供server服务，然后reduce，启动shuff-client客户端，去服务端拉取数据汇总，这个地方是循环链表的一个操作，但一时半会看不出什么问题，心想是个问题，看看网上是否已经有朋友遇到过，在google上一搜，果然有几个关于spark executor执行任务hang住的jira的bug，最后找到了下面的issue：

https://issues.apache.org/jira/browse/SPARK-18971
https://github.com/netty/netty/issues/6153

根本是netty的问题，在链表循环那个方法里面，会有几率出现链表闭链的bug，一旦形成循环链表就会hang住任务，从而导致整个Job无法执行完。具体的描述，大家可参考上面的jira连接。

影响的版本，理论上说只要是Netty4.0.43.Final之前的版本，所有的依赖netty的该版本的框架，都有几率触发。

解决办法：

升级spark2.1.0为 2.1.2,  2.1.3,或者2.2.0的版本






# Share



如果在使用brew安装软件的时候，特别慢，可以重新换个brew的下载源，有点类似yum的机制：

如果已经卡住了，请按Ctrl+C退出，mac上注意看好是control，别按成Command+C了，我就犯了这低级错误
。

```
# 进入brew主目录
$ cd `brew --repo`

# 更换镜像
$ git remote set-url origin https://git.coding.net/homebrew/homebrew.git

# 测试效果
$ brew update
```

其他的源：

```
https://git.coding.net/homebrew/homebrew.git - Coding
https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git - 清华
https://mirrors.ustc.edu.cn/brew.git - 中科大
```




